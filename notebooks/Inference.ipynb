{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b525201",
   "metadata": {},
   "source": [
    "## INFERENCE NOTEBOOK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637278f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules\n",
    "\n",
    "import os\n",
    "import tensorflow as tf \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from skimage import transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee638358",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "tf.random.set_seed(SEED) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b771724",
   "metadata": {},
   "source": [
    "## Predicting from a directory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c13d336d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# our root dataset dir path\n",
    "data_dir = \"../dataset/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8542ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model\n",
    "MODEL_PATH = '../trained_model_imagenet'\n",
    "\n",
    "model = tf.keras.models.load_model(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d62b2323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the total classes\n",
    "num_classes=7\n",
    "\n",
    "# the labels indexes\n",
    "classes = [\n",
    "    'boots', \n",
    "    'flip_flops',\n",
    "    'loafers',\n",
    "    'sandals',\n",
    "    'sneakers',\n",
    "    'soccer_shoes',\n",
    "    'no_shoe'\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bfaa957",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data real-time augmentation configuration that does normalization\n",
    "valid_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "121eaae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 350 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Instantiating generators of augmented image batches (and their labels)\n",
    "test_dir = os.path.join(data_dir, 'val')\n",
    "test_gen = valid_data_gen.flow_from_directory(test_dir,\n",
    "                                           target_size=(256, 256),\n",
    "                                           classes=classes,\n",
    "                                           class_mode='categorical',\n",
    "                                           shuffle=False,\n",
    "                                           seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a9583ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 213s 18s/step\n"
     ]
    }
   ],
   "source": [
    "# reset the data generator\n",
    "test_gen.reset()\n",
    "\n",
    "# predict on the data\n",
    "pred = model.predict(test_gen,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8bdb4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get filenames of the data images\n",
    "filenames = test_gen.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6be38031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predicted indexes\n",
    "predicted_class_indices = np.argmax(pred,axis=1)\n",
    "\n",
    "# get predicted labels\n",
    "predictions = [k for k in predicted_class_indices]\n",
    "\n",
    "outputs = [classes[ind] for ind in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c890996e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Filename</th>\n",
       "      <th>Predicted Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>boots\\280-bootsshoe.png</td>\n",
       "      <td>boots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>boots\\281-bootsshoe.png</td>\n",
       "      <td>boots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boots\\282-bootsshoe.png</td>\n",
       "      <td>boots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boots\\283-bootsshoe.png</td>\n",
       "      <td>boots</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>boots\\284-bootsshoe.png</td>\n",
       "      <td>boots</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Filename Predicted Label\n",
       "0  boots\\280-bootsshoe.png           boots\n",
       "1  boots\\281-bootsshoe.png           boots\n",
       "2  boots\\282-bootsshoe.png           boots\n",
       "3  boots\\283-bootsshoe.png           boots\n",
       "4  boots\\284-bootsshoe.png           boots"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a dataframe with the filenames and output labels\n",
    "\n",
    "out_list = [[filename,output] for filename,output in zip(filenames, outputs)]\n",
    "\n",
    "df = pd.DataFrame(out_list, columns=['Filename', 'Predicted Label'])\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "336f7f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svae the dataframe to a csv\n",
    "\n",
    "df.to_csv('../predictions/predictions.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e94cb69",
   "metadata": {},
   "source": [
    "## Predicting for a list of  Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17abd755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(filename):\n",
    "    '''\n",
    "        Input: ImagePath\n",
    "        Output : Process image array\n",
    "    '''\n",
    "    np_image = Image.open(filename) # open image\n",
    "    np_image = np.array(np_image).astype('float32')/255 # normalize image\n",
    "    np_image = transform.resize(np_image, (256, 256, 3)) # resize image\n",
    "    np_image = np.expand_dims(np_image, axis=0)\n",
    "    return np_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "576e092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(image_paths,model,classes):\n",
    "    '''\n",
    "        Input: List of image local paths or URLs\n",
    "        Output : List of predicted labels\n",
    "    '''\n",
    "    \n",
    "    response = []\n",
    "    for image_path in image_paths:\n",
    "        image = load(image_path) # process image\n",
    "        preds = model.predict(image) # predict label index\n",
    "        output = classes[np.argmax(preds,axis=1)[0]] # get the label\n",
    "        response.append(output)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9a2bf62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boots', 'boots']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths = ['..\\\\dataset\\\\val\\\\boots\\\\280-bootsshoe.png','..\\\\dataset\\\\val\\\\boots\\\\281-bootsshoe.png']\n",
    "classify_image(image_paths,model,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00d95350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
